#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TimeLapse@Desk Demo (ä¼˜åŒ–ç‰ˆ + æ°´å°åŠŸèƒ½)
è‡ªåŠ¨æ‹ç…§å’Œäººè„¸å¯¹é½å¤„ç†çš„æ¼”ç¤ºç¨‹åº - é’ˆå¯¹é€Ÿåº¦è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¢åŠ äº†æ°´å°åŠŸèƒ½
"""

import cv2
import numpy as np
import os
from datetime import datetime
import mediapipe as mp
import argparse

class TimeLapseCamera:
    def __init__(self, output_dir="photos", aligned_dir="aligned_photos"):
        """
        åˆå§‹åŒ–TimeLapseç›¸æœº
        
        Args:
            output_dir: åŸå§‹ç…§ç‰‡ä¿å­˜ç›®å½•
            aligned_dir: å¯¹é½åç…§ç‰‡ä¿å­˜ç›®å½•
        """
        self.output_dir = output_dir
        self.aligned_dir = aligned_dir
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(aligned_dir, exist_ok=True)
        
        # MediaPipeç›¸å…³å˜é‡ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ä»¥æé«˜å¯åŠ¨é€Ÿåº¦ï¼‰
        self.mp_face_detection = None
        self.mp_face_mesh = None
        self.mp_drawing = None
        self.face_detection = None
        self.face_mesh = None
        self._mediapipe_initialized = False
    
    def _init_mediapipe(self):
        """
        å»¶è¿Ÿåˆå§‹åŒ–MediaPipeï¼ˆåªæœ‰åœ¨éœ€è¦äººè„¸æ£€æµ‹æ—¶æ‰åˆå§‹åŒ–ï¼‰
        """
        if not self._mediapipe_initialized:
            print("æ­£åœ¨åˆå§‹åŒ–äººè„¸æ£€æµ‹æ¨¡å‹...")
            self.mp_face_detection = mp.solutions.face_detection
            self.mp_face_mesh = mp.solutions.face_mesh
            self.mp_drawing = mp.solutions.drawing_utils
            
            # åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨
            self.face_detection = self.mp_face_detection.FaceDetection(
                model_selection=0, min_detection_confidence=0.5)
            self.face_mesh = self.mp_face_mesh.FaceMesh(
                static_image_mode=True,
                max_num_faces=1,
                refine_landmarks=True,
                min_detection_confidence=0.5)
            
            self._mediapipe_initialized = True
            print("äººè„¸æ£€æµ‹æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    
    def _add_watermark(self, image, timestamp, alpha=0.7):
        """
        åœ¨å›¾åƒå³ä¸‹è§’æ·»åŠ åŠé€æ˜æ°´å°
        
        Args:
            image: è¾“å…¥å›¾åƒ
            timestamp: æ—¶é—´æˆ³å­—ç¬¦ä¸²
            alpha: é€æ˜åº¦ (0.0-1.0ï¼Œ0ä¸ºå®Œå…¨é€æ˜ï¼Œ1ä¸ºå®Œå…¨ä¸é€æ˜)
            
        Returns:
            numpy.ndarray: æ·»åŠ æ°´å°åçš„å›¾åƒ
        """
        # å¤åˆ¶å›¾åƒä»¥é¿å…ä¿®æ”¹åŸå›¾
        watermarked_image = image.copy()
        
        # æ°´å°æ–‡æœ¬ - ä½¿ç”¨ç¨³å®šçš„ç‰ˆæƒæ ‡è®°
        copyright_text = "Copyright Murphy" 
        time_text = timestamp
        
        # å­—ä½“è®¾ç½® - ä½¿ç”¨æ›´æ¸…æ™°çš„å­—ä½“
        font = cv2.FONT_HERSHEY_DUPLEX  # æ›´æ¥è¿‘Consolasçš„ç­‰å®½å­—ä½“æ•ˆæœ
        font_scale = 0.6
        thickness = 1
        color = (255, 255, 255)  # ç™½è‰²
        
        # è·å–å›¾åƒå°ºå¯¸
        height, width = watermarked_image.shape[:2]
        
        # è®¡ç®—æ–‡æœ¬å°ºå¯¸
        (copyright_w, copyright_h), _ = cv2.getTextSize(copyright_text, font, font_scale, thickness)
        (time_w, time_h), _ = cv2.getTextSize(time_text, font, font_scale, thickness)
        
        # è®¾ç½®æ°´å°ä½ç½®ï¼ˆè·ç¦»è¾¹ç•Œæœ‰ä¸€å®šè·ç¦»ï¼‰
        margin_right = 30  # è·ç¦»å³è¾¹ç•Œ
        margin_bottom = 30  # è·ç¦»ä¸‹è¾¹ç•Œ
        line_spacing = 8   # è¡Œé—´è·
        
        copyright_x = width - copyright_w - margin_right
        copyright_y = height - time_h - margin_bottom - line_spacing
        time_x = width - time_w - margin_right  
        time_y = height - margin_bottom
        
        # åˆ›å»ºé€æ˜å±‚
        overlay = watermarked_image.copy()
        
        # åœ¨é€æ˜å±‚ä¸Šç»˜åˆ¶æ–‡å­—ï¼ˆæ— æè¾¹ï¼Œæ¸…æ™°æ•ˆæœï¼‰
        cv2.putText(overlay, copyright_text, (copyright_x, copyright_y), 
                   font, font_scale, color, thickness, cv2.LINE_AA)
        cv2.putText(overlay, time_text, (time_x, time_y), 
                   font, font_scale, color, thickness, cv2.LINE_AA)
        
        # ä½¿ç”¨alphaæ··åˆå®ç°é€æ˜æ•ˆæœ
        cv2.addWeighted(overlay, alpha, watermarked_image, 1 - alpha, 0, watermarked_image)
        
        return watermarked_image
    
    def _display_camera_settings(self, cap):
        """
        æ˜¾ç¤ºæ‘„åƒå¤´å®é™…è®¾ç½®çš„å‚æ•°
        """
        print("æ‘„åƒå¤´å½“å‰è®¾ç½®:")
        print(f"  åˆ†è¾¨ç‡: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}")
        print(f"  å¸§ç‡: {cap.get(cv2.CAP_PROP_FPS):.1f} FPS")
        print(f"  äº®åº¦: {cap.get(cv2.CAP_PROP_BRIGHTNESS):.2f}")
        print(f"  å¯¹æ¯”åº¦: {cap.get(cv2.CAP_PROP_CONTRAST):.2f}")
        print(f"  é¥±å’Œåº¦: {cap.get(cv2.CAP_PROP_SATURATION):.2f}")
        print(f"  é”åº¦: {cap.get(cv2.CAP_PROP_SHARPNESS):.2f}")
        print(f"  æ›å…‰: {cap.get(cv2.CAP_PROP_EXPOSURE):.2f}")
        print(f"  å¢ç›Š: {cap.get(cv2.CAP_PROP_GAIN):.2f}")
        print(f"  è‡ªåŠ¨å¯¹ç„¦: {'å¼€å¯' if cap.get(cv2.CAP_PROP_AUTOFOCUS) else 'å…³é—­'}")
        print(f"  è‡ªåŠ¨ç™½å¹³è¡¡: {'å¼€å¯' if cap.get(cv2.CAP_PROP_AUTO_WB) else 'å…³é—­'}")
    
    def capture_photo(self, camera_index=0):
        """
        æ‹æ‘„ç…§ç‰‡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            camera_index: æ‘„åƒå¤´ç´¢å¼•ï¼Œé»˜è®¤ä¸º0
            
        Returns:
            tuple: (æˆåŠŸæ ‡å¿—, ç…§ç‰‡æ•°ç»„, æ–‡ä»¶å)
        """
        try:
            print("æ­£åœ¨åˆå§‹åŒ–æ‘„åƒå¤´...")
            # åˆå§‹åŒ–æ‘„åƒå¤´
            cap = cv2.VideoCapture(camera_index)
            if not cap.isOpened():
                print("é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                return False, None, None
            
            # è®¾ç½®æ‘„åƒå¤´å‚æ•°ï¼ˆæœ€å¤§åŒ–å›¾åƒè´¨é‡ï¼‰
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)   # æœ€å¤§åˆ†è¾¨ç‡
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)       # å‡å°‘ç¼“å†²åŒºå»¶è¿Ÿ
            cap.set(cv2.CAP_PROP_FPS, 30)             # é€‚ä¸­å¸§ç‡
            
            # å›¾åƒè´¨é‡ä¼˜åŒ–è®¾ç½®ï¼ˆé’ˆå¯¹ä½ çš„æ‘„åƒå¤´ç‰¹ç‚¹ä¼˜åŒ–ï¼‰
            # åªè®¾ç½®æ‘„åƒå¤´å®é™…æ”¯æŒçš„å‚æ•°
            try:
                cap.set(cv2.CAP_PROP_BRIGHTNESS, 128)     # ä¿æŒé»˜è®¤äº®åº¦
                cap.set(cv2.CAP_PROP_CONTRAST, 140)       # ç¨å¾®æé«˜å¯¹æ¯”åº¦
                cap.set(cv2.CAP_PROP_SATURATION, 145)     # ç¨å¾®æé«˜é¥±å’Œåº¦
                cap.set(cv2.CAP_PROP_SHARPNESS, 140)      # æé«˜é”åº¦
            except:
                print("æŸäº›å›¾åƒå‚æ•°è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            
            # å°è¯•å¯ç”¨è‡ªåŠ¨åŠŸèƒ½ï¼ˆå¦‚æœæ”¯æŒçš„è¯ï¼‰
            try:
                cap.set(cv2.CAP_PROP_AUTO_WB, 1)          # å°è¯•å¯ç”¨è‡ªåŠ¨ç™½å¹³è¡¡
                cap.set(cv2.CAP_PROP_AUTOFOCUS, 1)        # å°è¯•å¯ç”¨è‡ªåŠ¨å¯¹ç„¦
            except:
                pass  # å¦‚æœä¸æ”¯æŒå°±å¿½ç•¥
            
            print("æ‘„åƒå¤´å‚æ•°è®¾ç½®å®Œæˆï¼Œæ­£åœ¨ä¼˜åŒ–å›¾åƒè´¨é‡...")
            
            # æ˜¾ç¤ºå®é™…è®¾ç½®çš„å‚æ•°
            self._display_camera_settings(cap)
            
            print("æ‘„åƒå¤´é¢„çƒ­ä¸­...")
            # é¢„çƒ­æ‘„åƒå¤´ï¼Œè®©ç›¸æœºè°ƒæ•´åˆ°æœ€ä½³çŠ¶æ€ï¼ˆæé«˜ç…§ç‰‡è´¨é‡ï¼‰
            for i in range(10):  # å¢åŠ é¢„çƒ­å¸§æ•°ï¼Œè®©ç›¸æœºå……åˆ†è°ƒæ•´
                ret, frame = cap.read()
                if not ret:
                    print(f"é¢„çƒ­ç¬¬{i+1}å¸§å¤±è´¥")
                    break
                # æ˜¾ç¤ºé¢„çƒ­è¿›åº¦
                if (i + 1) % 3 == 0:
                    print(f"é¢„çƒ­ä¸­... {i+1}/10")
            
            # é¢å¤–ç­‰å¾…ï¼Œè®©è‡ªåŠ¨å¯¹ç„¦å’Œæ›å…‰ç¨³å®š
            import time
            time.sleep(1)  # ç­‰å¾…1ç§’è®©ç›¸æœºç¨³å®š
            
            print("æ­£åœ¨æ‹æ‘„...")
            # æ‹æ‘„æœ€ç»ˆç…§ç‰‡
            ret, frame = cap.read()
            cap.release()
            
            if not ret:
                print("é”™è¯¯ï¼šæ— æ³•æ‹æ‘„ç…§ç‰‡")
                return False, None, None
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆåŸºäºå½“å‰æ—¶é—´ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"photo_{timestamp}.jpg"
            filepath = os.path.join(self.output_dir, filename)
            
            # æ·»åŠ æ°´å°
            watermark_time = datetime.now().strftime("%Y/%m/%d %H:%M")
            watermark_time_place = watermark_time + " Xi'An"
            watermarked_frame = self._add_watermark(frame, watermark_time_place)
            
            # ä¿å­˜å¸¦æ°´å°çš„åŸå§‹ç…§ç‰‡
            cv2.imwrite(filepath, watermarked_frame)
            print(f"ç…§ç‰‡å·²ä¿å­˜: {filepath}")
            
            # è¿”å›æ— æ°´å°çš„åŸå§‹å›¾åƒä¾›åç»­å¯¹é½å¤„ç†ä½¿ç”¨
            return True, frame, filename
            
        except Exception as e:
            print(f"æ‹ç…§è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return False, None, None
    
    def detect_face_landmarks(self, image):
        """
        æ£€æµ‹äººè„¸å…³é”®ç‚¹
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            dict: åŒ…å«å…³é”®ç‚¹ä¿¡æ¯çš„å­—å…¸
        """
        # ç¡®ä¿MediaPipeå·²åˆå§‹åŒ–
        self._init_mediapipe()
        
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_mesh.process(rgb_image)
        
        if not results.multi_face_landmarks:
            return None
        
        # è·å–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
        face_landmarks = results.multi_face_landmarks[0]
        
        # è½¬æ¢å…³é”®ç‚¹åæ ‡
        h, w, _ = image.shape
        landmarks = []
        for landmark in face_landmarks.landmark:
            x = int(landmark.x * w)
            y = int(landmark.y * h)
            landmarks.append((x, y))
        
        # è·å–é‡è¦çš„å…³é”®ç‚¹
        # çœ¼ç›å…³é”®ç‚¹
        left_eye = landmarks[33]   # å·¦çœ¼
        right_eye = landmarks[263] # å³çœ¼
        # é¼»å°–
        nose_tip = landmarks[1]
        # å˜´è§’
        mouth_left = landmarks[61]
        mouth_right = landmarks[291]
        
        return {
            'all_landmarks': landmarks,
            'left_eye': left_eye,
            'right_eye': right_eye,
            'nose_tip': nose_tip,
            'mouth_left': mouth_left,
            'mouth_right': mouth_right
        }
    
    def align_face(self, image, landmarks, target_size=(1920, 1080)):
        """
        å¯¹é½äººè„¸åˆ°å›ºå®šä½ç½®ï¼ˆä¸ç¼©æ”¾ï¼Œåªå¹³ç§»å’Œæ—‹è½¬ï¼‰
        
        Args:
            image: è¾“å…¥å›¾åƒ
            landmarks: äººè„¸å…³é”®ç‚¹
            target_size: ç›®æ ‡å›¾åƒå°ºå¯¸ï¼Œé»˜è®¤1920*1080
            
        Returns:
            numpy.ndarray: å¯¹é½åçš„å›¾åƒ
        """
        if landmarks is None:
            return None
        
        # è·å–å…³é”®ç‚¹
        left_eye = np.array(landmarks['left_eye'])
        right_eye = np.array(landmarks['right_eye'])
        nose_tip = np.array(landmarks['nose_tip'])
        
        # è®¡ç®—çœ¼ç›ä¸­å¿ƒç‚¹
        eye_center = (left_eye + right_eye) / 2
        
        # è®¡ç®—çœ¼ç›ä¹‹é—´çš„è§’åº¦ï¼ˆç”¨äºæ—‹è½¬å¯¹é½ï¼‰
        eye_vector = right_eye - left_eye
        angle = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))
        
        # å®šä¹‰å›ºå®šçš„ç›®æ ‡ä½ç½®ï¼ˆå…³é”®ç‚¹åº”è¯¥å¯¹é½åˆ°çš„ä½ç½®ï¼‰
        target_eye_center = np.array([target_size[0] / 2, target_size[1] * 0.4])  # çœ¼ç›ä¸­å¿ƒåœ¨å›¾åƒä¸Šéƒ¨40%å¤„
        
        # åˆ›å»ºå˜æ¢çŸ©é˜µï¼šåªæ—‹è½¬ï¼Œä¸ç¼©æ”¾ï¼ˆscale=1.0ï¼‰
        rotation_matrix = cv2.getRotationMatrix2D(tuple(eye_center), angle, 1.0)
        
        # è®¡ç®—å¹³ç§»é‡ï¼Œå°†çœ¼ç›ä¸­å¿ƒç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
        tx = target_eye_center[0] - eye_center[0]
        ty = target_eye_center[1] - eye_center[1]
        rotation_matrix[0, 2] += tx
        rotation_matrix[1, 2] += ty
        
        # åº”ç”¨å˜æ¢ï¼Œè¶…å‡ºéƒ¨åˆ†è£åˆ‡ï¼Œç©ºç™½éƒ¨åˆ†å¡«å……é»‘è‰²
        aligned_image = cv2.warpAffine(
            image, 
            rotation_matrix, 
            target_size,
            borderMode=cv2.BORDER_CONSTANT,  # è¾¹ç•Œå¡«å……æ¨¡å¼
            borderValue=(0, 0, 0)            # é»‘è‰²å¡«å……
        )
        
        return aligned_image
    
    def process_photo(self, image, filename):
        """
        å¤„ç†ç…§ç‰‡ï¼šæ£€æµ‹äººè„¸å¹¶å¯¹é½
        
        Args:
            image: è¾“å…¥å›¾åƒ
            filename: æ–‡ä»¶å
            
        Returns:
            bool: å¤„ç†æˆåŠŸæ ‡å¿—
        """
        try:
            # æ£€æµ‹äººè„¸å…³é”®ç‚¹
            landmarks = self.detect_face_landmarks(image)
            
            if landmarks is None:
                print("è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°äººè„¸ï¼Œè·³è¿‡å¯¹é½å¤„ç†")
                return False
            
            # å¯¹é½äººè„¸
            aligned_image = self.align_face(image, landmarks)
            
            if aligned_image is None:
                print("è­¦å‘Šï¼šäººè„¸å¯¹é½å¤±è´¥")
                return False
            
            # ä»æ–‡ä»¶åæå–æ—¶é—´æˆ³å¹¶æ ¼å¼åŒ–ä¸ºæ°´å°æ ¼å¼
            timestamp_str = filename.replace("photo_", "").replace(".jpg", "")
            try:
                # è§£ææ—¶é—´æˆ³ 20250926_143022 -> 2025/09/26 14:30
                dt = datetime.strptime(timestamp_str, "%Y%m%d_%H%M%S")
                watermark_time = dt.strftime("%Y/%m/%d %H:%M")
            except:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                watermark_time = datetime.now().strftime("%Y/%m/%d %H:%M")
            
            # æ·»åŠ åœ°ç‚¹ä¿¡æ¯åˆ°æ—¶é—´éƒ¨åˆ†
            watermark_time_place = watermark_time + " Xi'An"
            
            # ä¸ºå¯¹é½å›¾åƒæ·»åŠ æ°´å°
            watermarked_aligned = self._add_watermark(aligned_image, watermark_time_place)
            
            # ä¿å­˜å¸¦æ°´å°çš„å¯¹é½åå›¾åƒ
            aligned_filename = f"aligned_{filename}"
            aligned_filepath = os.path.join(self.aligned_dir, aligned_filename)
            cv2.imwrite(aligned_filepath, watermarked_aligned)
            print(f"å¯¹é½ç…§ç‰‡å·²ä¿å­˜: {aligned_filepath}")
            
            return True
            
        except Exception as e:
            print(f"å¤„ç†ç…§ç‰‡æ—¶å‡ºç°é”™è¯¯: {e}")
            return False
    
    def take_daily_photo(self):
        """
        æ‰§è¡Œæ¯æ—¥æ‹ç…§æµç¨‹ï¼ˆè‡ªåŠ¨åŒ–å®Œæ•´æµç¨‹ï¼‰
        """
        print("=== TimeLapse@Desk è‡ªåŠ¨æ‹ç…§å¯¹é½ ===")
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # 1. æ‹æ‘„ç…§ç‰‡
        print("æ­£åœ¨æ‹æ‘„ç…§ç‰‡...")
        success, image, filename = self.capture_photo()
        
        if not success:
            print("æ‹ç…§å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            return False
        
        # 2. è‡ªåŠ¨è¿›è¡Œäººè„¸å¯¹é½å¤„ç†
        print("æ­£åœ¨è¿›è¡Œäººè„¸å¯¹é½...")
        process_success = self.process_photo(image, filename)
        
        if process_success:
            print("âœ… æ‹ç…§å’Œå¯¹é½å®Œæˆï¼")
        else:
            print("âš ï¸ äººè„¸å¯¹é½å¤±è´¥ï¼Œä½†åŸå§‹ç…§ç‰‡å·²ä¿å­˜")
        
        print(f"ğŸ“ åŸå§‹ç…§ç‰‡: {self.output_dir}")
        print(f"ğŸ“ å¯¹é½ç…§ç‰‡: {self.aligned_dir}")
        
        return True

def main():
    """ä¸»å‡½æ•° - è‡ªåŠ¨åŒ–æ‹ç…§å¯¹é½æµç¨‹"""
    parser = argparse.ArgumentParser(description='TimeLapse@Desk è‡ªåŠ¨æ‹ç…§å¯¹é½ç¨‹åº')
    parser.add_argument('--camera', type=int, default=0, help='æ‘„åƒå¤´ç´¢å¼• (é»˜è®¤: 0)')
    parser.add_argument('--output', type=str, default='photos', help='åŸå§‹ç…§ç‰‡ä¿å­˜ç›®å½•')
    parser.add_argument('--aligned', type=str, default='aligned_photos', help='å¯¹é½ç…§ç‰‡ä¿å­˜ç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºTimeLapseç›¸æœºå®ä¾‹
    camera = TimeLapseCamera(args.output, args.aligned)
    
    # æ‰§è¡Œè‡ªåŠ¨åŒ–æ‹ç…§å¯¹é½æµç¨‹
    camera.take_daily_photo()

if __name__ == "__main__":
    main()